<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Enhancing high depth-of-field photos with image understanding">
    <meta name="description" content="I use ML model predictions for photo depth and foreground saliency to highlight the subject(s) of interest against a soft background.">
  <meta property="og:description" content="I use ML model predictions for photo depth and foreground saliency to highlight the subject(s) of interest against a soft background.">
    <meta property="og:type" content="blog">
  <title>Enhancing high depth-of-field photos with image understanding</title>
  <!-- Favicon -->
    <link rel="shortcut icon" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F320633e8-3085-4580-acbd-ebf160eeed36%2Fhome.png?table=collection&id=c028b1e3-fce7-415e-96c6-cf8b2be3919a">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }

    hr.style14 { 
      border: 0; 
      height: 1px; 
      background-image: -webkit-linear-gradient(left, #f0f0f0, #8c8b8b, #f0f0f0);
      background-image: -moz-linear-gradient(left, #f0f0f0, #8c8b8b, #f0f0f0);
      background-image: -ms-linear-gradient(left, #f0f0f0, #8c8b8b, #f0f0f0);
      background-image: -o-linear-gradient(left, #f0f0f0, #8c8b8b, #f0f0f0); 
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index.html">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F320633e8-3085-4580-acbd-ebf160eeed36%2Fhome.png?table=collection&id=c028b1e3-fce7-415e-96c6-cf8b2be3919a"></span> <span>Blog</span></div>
    </a>
                                            <span class="Navbar__Delim">&centerdot;</span>
    <a href="about.html">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff0df78d3-1d44-498e-8227-78001f637913%2Fabout.png?table=block&id=b5ef726c-6168-43f7-ab47-4080e6397bed"></span> <span>About</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="photography.html">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F34a8a292-8ecd-460a-9845-834872a45c7a%2Fcamera.png?table=block&id=81e721b8-8434-44d4-a045-f04a6894fadc"></span> <span>Photography</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="quotes.html">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff364b72f-6d19-42ce-a239-0a4a25f6ac34%2Fquotes.png?table=block&id=fd698c32-d385-4104-9351-e3b2d84f8e45"></span> <span>Quotes</span></div>
    </a>
                  </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    <h1 class="Header__Title">Enhancing high depth-of-field photos with image understanding</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted by <i><a href="about.html">Sesh</a></i> on Mon, Aug 26, 2019</span>
                          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--yellow">
            <a href="tag/machine-learning.html">machine-learning</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--purple">
            <a href="tag/tech.html">tech</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--red">
            <a href="tag/photography.html">photography</a>
          </span>
                  </div>
          </header>
      <article id="https://www.notion.so/d681b1ea24374387a8fda2346bf78d38" class="PageRoot"><blockquote id="https://www.notion.so/ecef14cd03394342a56352edf9f716da" class="ColorfulBlock ColorfulBlock--ColorDefault Quote"><span class="SemanticStringArray"><span class="SemanticString">TLDR: I use ML model predictions for photo depth and foreground saliency to highlight the subject(s) of interest against a soft background. Sample results below.
Code is </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/seshadrs/ml-photo-filter"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">here</strong></a></span><span class="SemanticString">.</span></span></blockquote><div id="https://www.notion.so/3c98f68714134019aa59fc3980e5197b" class="ColumnList"><div id="https://www.notion.so/929ee79fc55c416bb21434bd51968c25" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/e7d0121586d54be8ba13ab0fe650e8f3" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F61a164bd-8752-4e8a-9ae3-ee7866b0e6a5%2FIMG_20171117_233051.jpg?width=2448&amp;table=block&amp;id=e7d01215-86d5-4be8-ba13-ab0fe650e8f3"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F61a164bd-8752-4e8a-9ae3-ee7866b0e6a5%2FIMG_20171117_233051.jpg?width=2448&amp;table=block&amp;id=e7d01215-86d5-4be8-ba13-ab0fe650e8f3" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input (iPhone XR)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/40f9ca0ced8d4f4ebb41eacbccde95c6" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/dcfd0777b7c241b0bd94b2b6c4be6a7c" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d818420-ab6a-4aaa-a6d6-e682bb290def%2Fresult_me_nz_hike.png?width=2448&amp;table=block&amp;id=dcfd0777-b7c2-41b0-bd94-b2b6c4be6a7c"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d818420-ab6a-4aaa-a6d6-e682bb290def%2Fresult_me_nz_hike.png?width=2448&amp;table=block&amp;id=dcfd0777-b7c2-41b0-bd94-b2b6c4be6a7c" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/2213c122f34d4171be9ad1b39fd5c03f" class="ColumnList"><div id="https://www.notion.so/a21616fd6ae04411b6b259d784e8b29b" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/703cb52f11d24a78af85ecca3fd93d61" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F56b02e22-f685-4d50-b3bf-0117e039a8ec%2Fforest_gump.jpeg?width=1136&amp;table=block&amp;id=703cb52f-11d2-4a78-af85-ecca3fd93d61"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F56b02e22-f685-4d50-b3bf-0117e039a8ec%2Fforest_gump.jpeg?width=1136&amp;table=block&amp;id=703cb52f-11d2-4a78-af85-ecca3fd93d61" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input (Forest Gump)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/afc59fddda034af5bc4d3d9203cf3d85" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/27d73afad7e349d99b757900d3724dcb" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F760d415c-b773-476b-ad0a-b7413bd4f7ab%2Fresult_no_grad.png?width=1136&amp;table=block&amp;id=27d73afa-d7e3-49d9-9b75-7900d3724dcb"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F760d415c-b773-476b-ad0a-b7413bd4f7ab%2Fresult_no_grad.png?width=1136&amp;table=block&amp;id=27d73afa-d7e3-49d9-9b75-7900d3724dcb" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/31617fd43d054fc2b4cd5ad54149c688" class="ColumnList"><div id="https://www.notion.so/5a47358b8f1c41dfb3b0c8d321b867f2" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/3cefb4c3b12642ffa0dbce9f61d6519a" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Febd559a5-6119-4241-8689-1a39cda24b5f%2FIMG_4306.jpg?width=4032&amp;table=block&amp;id=3cefb4c3-b126-42ff-a0db-ce9f61d6519a"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Febd559a5-6119-4241-8689-1a39cda24b5f%2FIMG_4306.jpg?width=4032&amp;table=block&amp;id=3cefb4c3-b126-42ff-a0db-ce9f61d6519a" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input (iPhone XR)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/35830abfa2264ea9bdbbc86068d4f669" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/7e9704f8697543f790beb44c70788a36" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53e8247c-7567-4f6f-ad22-06e4e2ab86a6%2Fresult_with_grad.png?width=4032&amp;table=block&amp;id=7e9704f8-6975-43f7-90be-b44c70788a36"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53e8247c-7567-4f6f-ad22-06e4e2ab86a6%2Fresult_with_grad.png?width=4032&amp;table=block&amp;id=7e9704f8-6975-43f7-90be-b44c70788a36" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result </span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/757d3887b750463d92d7386904cd81c4" class="ColumnList"><div id="https://www.notion.so/32eb8e33e81e418e9aaa748e4e0c0e34" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/ece22e1ddde94015abf024e20b0fc942" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d4d692c-9ce0-4280-ba26-2b3c3dfe1bd1%2FIMG_5279.jpg?width=1512&amp;table=block&amp;id=ece22e1d-dde9-4015-abf0-24e20b0fc942"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d4d692c-9ce0-4280-ba26-2b3c3dfe1bd1%2FIMG_5279.jpg?width=1512&amp;table=block&amp;id=ece22e1d-dde9-4015-abf0-24e20b0fc942" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input (iPhone XR)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/43d21bad416044bc91f9fa2269428301" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/30d6439c425d431387e761ff19c50af4" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3bc71c46-e2a4-4511-8846-075a7a5b75c8%2Fresult_with_grad.png?width=1512&amp;table=block&amp;id=30d6439c-425d-4313-87e7-61ff19c50af4"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3bc71c46-e2a4-4511-8846-075a7a5b75c8%2Fresult_with_grad.png?width=1512&amp;table=block&amp;id=30d6439c-425d-4313-87e7-61ff19c50af4" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/d5ee150bc715471285b83ccbd36e0f45" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/4914e780ee014bf585c0f23906e33612" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/4914e780ee014bf585c0f23906e33612"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">a focus on depth</span></span></h3><div id="https://www.notion.so/eb0166bb93214a66a38b888b5f136ba5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">When light enters a camera through a tiny area (a.k.a high-aperture), the captured image has a high depth-of-field (DOF). This is typical for smartphones/action cameras that have tiny sensors or even interchangeable lens cameras paired with telephoto lenses that limit the amount of light that eventually gets through. In these photos you&#x27;ll notice that every part of the frame is in focus. It is detailed everywhere, and as a result can appear distracting or busy when there is a particular subject of interest in the frame. This is one of the reasons that bokeh is widely liked. But you need big expensive low-aperture lenses to transform background detail into silky color gradients. Maybe ML can help us approximate this and do even more without the expensive hardware. &lt;drumroll&gt;.</span></span></p></div><div id="https://www.notion.so/3abdd28461d6455980577724a5ce040e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/722940a63e8246828e7f0a5433527dc1" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/722940a63e8246828e7f0a5433527dc1"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">problem</span></span></h3><div id="https://www.notion.so/4848341c90784fccbfb83eac9f2b30fe" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">While making a photo scrapbook for a special someone I realized that most of my pictures are from the smartphone, all high DOF images. This was disappointing.  Let me explain. Our eyes gravitate to areas in focus (detail). When the entire image is sharp, the hint is that everything in the picture is important and needs attention. But most of our photos have a clear subject of interest in the foreground. Ideally we can shine focus on the subject and remove detail from the background so that the cognitive overhead of parsing the picture is minimal. The only purpose the background serves IMO is to provide some context to place that memory. Ideally the background in the resulting image will look dreamy and the processing won&#x27;t look janky.</span></span></p></div><div id="https://www.notion.so/ce25524f57754b1b95464e2164c5bf23" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/5799e904309a4f6ba21d10becd4ff2e0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/5799e904309a4f6ba21d10becd4ff2e0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">limitations of existing approaches</span></span></h3><div id="https://www.notion.so/2cd58bf6a12c4f9f8a06211d52cdde62" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Modern smartphones can apply on-device ML models to blur background for portrait photos. But the results are hit or miss, and come with compromises - speed, quality of output, limited applicability (only for human faces and in some cases pets) and added crop factor. As a post processing step however, we are not constrained by hardware, energy or time constraints and can overcome the above mentioned issues. Most importantly, I already have a repository of raw images that come from a variety of sources - a go pro, a smartphone and a mirrorless ILC.</span></span></p></div><div id="https://www.notion.so/7e4ce093e5244c0f94dcff0f0ba993be" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/037236a58d6d44f1b0fce328fc732d30" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/037236a58d6d44f1b0fce328fc732d30"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">example result</span></span></h3><div id="https://www.notion.so/d531f882299446ca98a8a47266581db2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Let&#x27;s dive into how we can do this. The image (1st pic) in this example is an extreme crop of a photo I captured with the Olympus EM5 II micro-four-thirds (small sensor) camera with a 300mm telephoto lens exposed at f/6.7 and 1/250th second. I only care about the two elk in the foreground here; however the grass and stones behind them are too detailed (and noisy) for my liking. In the result (2nd pic) you&#x27;ll see that the elk and entire foreground is kept intact. the background gracefully fades into what looks like a &quot;painting&quot; and appears more pleasing. This was created programmatically without any manual input. </span></span></p></div><div id="https://www.notion.so/a4b7e2258df84ce4841dd3fc5b5e47ba" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/3ccb631f6ed440e1a898289b78767499" class="ColumnList"><div id="https://www.notion.so/5f555fc0ecd8448bbfd394ae388871df" class="Column" style="width:calc((100% - var(--column-spacing) * 2) * 0.33333333333333337)"><div id="https://www.notion.so/d9953407e17c4cd08e4d1eecb8e1a1fa" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6d77e63d-6258-4d4f-979e-3c518045c67d%2Ftwo_elk_happy_copy.jpg?width=432&amp;table=block&amp;id=d9953407-e17c-4cd0-8e4d-1eecb8e1a1fa"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6d77e63d-6258-4d4f-979e-3c518045c67d%2Ftwo_elk_happy_copy.jpg?width=432&amp;table=block&amp;id=d9953407-e17c-4cd0-8e4d-1eecb8e1a1fa" style="width:432px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input</span></span></figcaption></figure></div></div><div id="https://www.notion.so/895a3cab2c5848039a776f3efd7807cd" class="Column" style="width:calc((100% - var(--column-spacing) * 2) * 0.33333333333333337)"><div id="https://www.notion.so/7a57079a32e8429fb07aeb13d1f1193c" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3b690628-1e9c-40f4-869d-b6025a0973dd%2Fresult_no_grad_elk_happy_copy.png?width=432&amp;table=block&amp;id=7a57079a-32e8-429f-b07a-eb13d1f1193c"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3b690628-1e9c-40f4-869d-b6025a0973dd%2Fresult_no_grad_elk_happy_copy.png?width=432&amp;table=block&amp;id=7a57079a-32e8-429f-b07a-eb13d1f1193c" style="width:432px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result</span></span></figcaption></figure></div></div><div id="https://www.notion.so/60376413adfa46f8939d02311a4030b5" class="Column" style="width:calc((100% - var(--column-spacing) * 2) * 0.3333333333333333)"><div id="https://www.notion.so/617634702be7497e9eacdafa2a000426" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc705a01b-febe-4f18-9098-a989ea646c53%2Fresult_with_grad.png?width=2780&amp;table=block&amp;id=61763470-2be7-497e-9eac-dafa2a000426"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc705a01b-febe-4f18-9098-a989ea646c53%2Fresult_with_grad.png?width=2780&amp;table=block&amp;id=61763470-2be7-497e-9eac-dafa2a000426" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result with alpha gradient</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/4cc4e6ef88a2485b9ca6b6fac07bb2b1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/c183f878d95d474d9ccc6ccf7b198a70" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/c183f878d95d474d9ccc6ccf7b198a70"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">intermediate steps</span></span></h3><div id="https://www.notion.so/01137a6296954514a2314164ff3138ee" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Lets take this photo of surfers below as an example to trace the image processing involved. </span></span></p></div><div id="https://www.notion.so/b6f4f6a4a5ff487b8cc82d4686c4c2cd" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0a845e73-cf8c-4859-b437-01287248cafb%2Fsurfers.jpg?width=384&amp;table=block&amp;id=b6f4f6a4-a5ff-487b-8cc8-2d4686c4c2cd"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0a845e73-cf8c-4859-b437-01287248cafb%2Fsurfers.jpg?width=384&amp;table=block&amp;id=b6f4f6a4-a5ff-487b-8cc8-2d4686c4c2cd" style="width:384px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input (</span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://pxhere.com/en/photo/1566807">source</a></span><span class="SemanticString"> under Creative Commons CC0)</span></span></figcaption></figure></div><div id="https://www.notion.so/7eb8e5348b394cddbcaa1e23d3002f01" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I use OpenCV Python bindings create a less detailed watercolor-like version of the image to use later as the background for compositing. We smooth the outline with an ellipse kernel and brighten dark areas. The parameters here are magic numbers tuned to my liking.</span></span></p></div><div id="https://www.notion.so/ea4c8ccc299344458c38521f417036cc" class="ColumnList"><div id="https://www.notion.so/b53183f1cc5744799876e49fb58b4ee4" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><pre id="https://www.notion.so/cb57a22c42254f1d9baccf933fcb76b4" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span><span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># reference: https://stackoverflow.com/questions/60016168/how-to-implement-a-photoshop-like-effect-oilpaint-effect-in-opencv</span>
<span class="token keyword">def</span> <span class="token function">to_watercolor_background_img</span><span class="token punctuation">(</span>img <span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">:</span>
    kernel <span class="token operator">=</span> cv2<span class="token punctuation">.</span>getStructuringElement<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>MORPH_ELLIPSE<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    morph <span class="token operator">=</span> cv2<span class="token punctuation">.</span>morphologyEx<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>MORPH_OPEN<span class="token punctuation">,</span> kernel<span class="token punctuation">)</span>
    <span class="token keyword">return</span> cv2<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>morph<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">,</span>cv2<span class="token punctuation">.</span>NORM_MINMAX<span class="token punctuation">)</span></span></span></span></code></pre></div><div id="https://www.notion.so/8189f3541d074fc28a5d6349287cd3cf" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/2c35901d4eb44b0b9a3e82ab66a0791e" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04cffb54-9362-43ad-a666-31512da81b81%2Fsurfers_watercolor.png?width=366&amp;table=block&amp;id=2c35901d-4eb4-4b0b-9a3e-82ab66a0791e"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04cffb54-9362-43ad-a666-31512da81b81%2Fsurfers_watercolor.png?width=366&amp;table=block&amp;id=2c35901d-4eb4-4b0b-9a3e-82ab66a0791e" style="width:366px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">dreamy painting filter applied</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/e11505fba779447182bbbf21661ed56e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I use a pertained </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/pdf/2005.09007.pdf">U2net DNN model</a></span><span class="SemanticString"> to detect salient objects in the image. This identifies salient objects in the image. In this case, the surfers and their boards. Potentially we could use this directly as a mask to composite the watercolor background image and the original. But as you can see in the composited result below, the crisp image of the surfers surrounded by the blurry background all-around them looks overtly artificial. This is not how optics works - everything in the focal plane must be crisp. What I&#x27;m looking for is a graceful transition. For this, I&#x27;ll need a depth map.</span></span></p></div><div id="https://www.notion.so/191be93ac26d4f519ed075edd48ef384" class="ColumnList"><div id="https://www.notion.so/0bb0241e839a47b7ba05fbbdb4c08e8f" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><pre id="https://www.notion.so/1454a797171f4cb48570e3c92f27441a" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>foreground_image <span class="token operator">=</span> foreground_detection<span class="token punctuation">(</span>input_image<span class="token punctuation">)</span>
alpha <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>foreground_image<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
foreground_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span></span></span></span></code></pre></div><div id="https://www.notion.so/2b69609667a34e24b0e021fe2ac0a50b" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/37e026c7b87a4a94be8a350ed4474d4e" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa62bd08b-10c3-4fae-b370-98dcbda2f791%2Fsurfers_foreground.png?width=384&amp;table=block&amp;id=37e026c7-b87a-4a94-be8a-350ed4474d4e"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa62bd08b-10c3-4fae-b370-98dcbda2f791%2Fsurfers_foreground.png?width=384&amp;table=block&amp;id=37e026c7-b87a-4a94-be8a-350ed4474d4e" style="width:384px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">foreground mask</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/7273e30d98a2475b810121239e8da068" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fce9f3ae6-3fe3-410a-a2e9-f6854714d9dd%2Fresult_no_grad.png?width=432&amp;table=block&amp;id=7273e30d-98a2-475b-8101-21239e8da068"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fce9f3ae6-3fe3-410a-a2e9-f6854714d9dd%2Fresult_no_grad.png?width=432&amp;table=block&amp;id=7273e30d-98a2-475b-8101-21239e8da068" style="width:432px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">foreground mask when used directly for compositing looks unnatural</span></span></figcaption></figure></div><div id="https://www.notion.so/f85bf99027044c3e892c3a8184696906" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I use a pertained </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1907.01341">MiDas model</a></span><span class="SemanticString"> to predict the depth map of the 2D (or monocular) image. The model outputs relative inverse depth, which I mix-max normalize so that the closest pixel has a value of 1 and the farthest is at 0. I can now combine this information with the foreground mask from above.</span></span></p></div><div id="https://www.notion.so/c436eb4e82634bec86e85f02a5d237fe" class="ColumnList"><div id="https://www.notion.so/95348753140742b8928da6050394d7a5" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><pre id="https://www.notion.so/2e16f343ab624485a9e8a23e035f1106" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>model_type <span class="token operator">=</span> <span class="token string">"DPT_Large"</span>     <span class="token comment"># MiDaS v3 - Large</span>
midas <span class="token operator">=</span> torch<span class="token punctuation">.</span>hub<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"intel-isl/MiDaS"</span><span class="token punctuation">,</span> model_type<span class="token punctuation">)</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
midas<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
midas<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
midas_transforms <span class="token operator">=</span> torch<span class="token punctuation">.</span>hub<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"intel-isl/MiDaS"</span><span class="token punctuation">,</span> <span class="token string">"transforms"</span><span class="token punctuation">)</span>
transform <span class="token operator">=</span> midas_transforms<span class="token punctuation">.</span>dpt_transform

<span class="token keyword">def</span> <span class="token function">to_depth_img</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_batch <span class="token operator">=</span> transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        prediction <span class="token operator">=</span> midas<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span>
        prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>
            prediction<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            size<span class="token operator">=</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            mode<span class="token operator">=</span><span class="token string">"bicubic"</span><span class="token punctuation">,</span>
            align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> prediction<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">normalize_0_1</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tmp <span class="token operator">=</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    tmp <span class="token operator">=</span> tmp <span class="token operator">-</span> <span class="token builtin">min</span><span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>
    tmp <span class="token operator">=</span> tmp<span class="token operator">/</span><span class="token builtin">max</span><span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tmp<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

depth_img <span class="token operator">=</span> normalize_0_1<span class="token punctuation">(</span>to_depth_img<span class="token punctuation">(</span>input_img<span class="token punctuation">)</span></span></span></span></code></pre></div><div id="https://www.notion.so/bc0e570186244b1b919c908c72915ca4" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/03f38f68b63a48c48e7ba9db5047117e" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb1596bae-27ad-47b3-8a4c-498f0e3799ee%2Fsurfers_depth.png?width=366&amp;table=block&amp;id=03f38f68-b63a-48c4-8e7b-a9db5047117e"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb1596bae-27ad-47b3-8a4c-498f0e3799ee%2Fsurfers_depth.png?width=366&amp;table=block&amp;id=03f38f68-b63a-48c4-8e7b-a9db5047117e" style="width:366px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">depth mask</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/19e7605860d247018453a3e55adf8c2f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I want to gracefully interpolate (i.e mix) the crisp source image with the blurry background image, so the result looks more &quot;natural&quot; to the eye. I use the normalized depth distribution of the foreground and background pixels to determine where to start and end this interpolation. I start at 50th percentile of the foreground mask depth and stop at the 50th percentile of the background mask depth. Within that range, the normalized depth value is used to combine the two images. Above that range (front), the original image is displayed, and below (back) it is the soft background. The 50th percentile values are just magic numbers; different values or non-linear functions for interpolation weighting might work better for different photos. Notice how the interpolation mask below does not have hard boundaries found in the foreground mask. The mask extends beyond the surfers and gradually fades away.</span></span></p></div><div id="https://www.notion.so/6e6a9da3459842049f8cf6e63e63bd1a" class="ColumnList"><div id="https://www.notion.so/312d00c4c24d4786a66de8ae58a02be5" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><pre id="https://www.notion.so/913f927a1cb94e44876af5e26ad46e91" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>interpolation_start_depth <span class="token operator">=</span> np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>foreground_depth_flat<span class="token punctuation">[</span>foreground_depth_flat<span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span>
interpolation_stop_depth <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>interpolation_start_depth<span class="token punctuation">,</span> np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>background_depth_flat<span class="token punctuation">[</span>background_depth_flat<span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
interpolation_width <span class="token operator">=</span> interpolation_start_depth <span class="token operator">-</span> interpolation_stop_depth

<span class="token keyword">def</span> <span class="token function">squish</span><span class="token punctuation">(</span>depth_val<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> depth_val<span class="token operator">></span>interpolation_start_depth<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">.</span>
    <span class="token keyword">elif</span> depth_val <span class="token operator">&lt;=</span> interpolation_stop_depth<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">.</span>
    <span class="token keyword">return</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>depth_val <span class="token operator">-</span> interpolation_stop_depth<span class="token punctuation">)</span><span class="token operator">/</span>interpolation_width<span class="token punctuation">)</span>

<span class="token comment"># Since the depth map and the foreground map often disagree on the traced edges</span>
<span class="token comment"># of objects, I add the normalized foreground mask to the depth mask to increase</span>
<span class="token comment"># the weight for the foreground pixels.</span>
interpolation_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vectorize<span class="token punctuation">(</span>squish<span class="token punctuation">)</span><span class="token punctuation">(</span>foreground_mask <span class="token operator">+</span> depth_img<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span></span></span></code></pre></div><div id="https://www.notion.so/0f71e092529e42bead573c58421afcb6" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/0794ad34c5404a09840a92a464f5a436" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcd19c049-66aa-4f62-8300-d853954caeb6%2Fsurfers_mask.png?width=366&amp;table=block&amp;id=0794ad34-c540-4a09-840a-92a464f5a436"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcd19c049-66aa-4f62-8300-d853954caeb6%2Fsurfers_mask.png?width=366&amp;table=block&amp;id=0794ad34-c540-4a09-840a-92a464f5a436" style="width:366px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Final interpolation mask</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/374213e2c2b94a6e8962bc77951d9a25" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The image composite with this new mask (1st pic below) IMO is better than the previous composite result. The shallow water in the front is crisp, so are the surfers and then the focus falls off more gracefully, revealing the soft background. Adding a right to left alpha gradient to the background image can (sometimes) create a more pleasing, &quot;dreamy&quot; result (2nd pic below); this is optional and a subjective preference. Save for the jagged edges around a couple of the surfers&#x27; heads I am happy with the result.</span></span></p></div><pre id="https://www.notion.so/246bb890e8454a1ea898060ec50960c2" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
result_without_grad <span class="token operator">=</span> Image<span class="token punctuation">.</span>composite<span class="token punctuation">(</span>input_img<span class="token punctuation">,</span> background_img<span class="token punctuation">,</span> interpolation_mask_img<span class="token punctuation">)</span>

background_img<span class="token punctuation">.</span>putalpha<span class="token punctuation">(</span>horizontal_gradient<span class="token punctuation">)</span>
result_with_grad <span class="token operator">=</span> Image<span class="token punctuation">.</span>composite<span class="token punctuation">(</span>input_img<span class="token punctuation">,</span> background_img<span class="token punctuation">,</span> interpolation_mask_img<span class="token punctuation">)</span></span></span></span></code></pre><div id="https://www.notion.so/7e8e99ef6eb1462a994ab8adbaf37e12" class="ColumnList"><div id="https://www.notion.so/0f098ca1f63e44ac83a16dbe6e203ea7" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/d9a5f57402e5428296767c9b51c81ffc" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe40f4c0d-9e42-4ebc-855c-0cd47fefe1ab%2Fresult_no_grad_surfers.png?width=384&amp;table=block&amp;id=d9a5f574-02e5-4282-9676-7c9b51c81ffc"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe40f4c0d-9e42-4ebc-855c-0cd47fefe1ab%2Fresult_no_grad_surfers.png?width=384&amp;table=block&amp;id=d9a5f574-02e5-4282-9676-7c9b51c81ffc" style="width:384px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result </span></span></figcaption></figure></div></div><div id="https://www.notion.so/2d083244508e48888a52f053bc1f2e2b" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/a3f47825b3904092b5398b51aeddb898" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2a1f0a19-6f61-4d30-8341-92e413c1f8ab%2Fresult_with_grad.png?width=1200&amp;table=block&amp;id=a3f47825-b390-4092-b539-8b51aeddb898"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2a1f0a19-6f61-4d30-8341-92e413c1f8ab%2Fresult_with_grad.png?width=1200&amp;table=block&amp;id=a3f47825-b390-4092-b539-8b51aeddb898" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result with horizontal gradient</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/3a4dd5151b794457b3f053dd617820fe" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/9827ffec68f24e3982924c8faaf9a184" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/9827ffec68f24e3982924c8faaf9a184"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">qualitative analysis</span></span></h3><div id="https://www.notion.so/23a4127160a94ac8b299ec09c3306b82" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">About 70% of the images I tried looked good or great to me. The rest I would characterize as poor or less than perfect results. These are the main failure modes:</span></span></p></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/cf8c780bcfc844eeb2da8bdf47e5351f" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"> low resolution input images or tiny subjects have poor foreground masks. These are typically an issue with extreme crops. Upscaling the image may alleviate these issues.</span></span></li><li id="https://www.notion.so/0248e8888f7646768cf72e661a64b415" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">lack of background detail in the input. These methods only make sense when the image is busy to begin with. When there is plenty of foreground-background separation already, a crisp foreground against an utterly blurry background looks unnatural. See the park ranger example below.</span></span></li><li id="https://www.notion.so/416e1188730549a0883eda4265e4c5df" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">The salient object detection model is far from perfect. Any mistakes in identifying objects (partially identified objects or misidentified objects) leads to unnatural results. See the buddha image below where the statue&#x27;s body is blurry but the face isn&#x27;t.</span></span></li></ol><div id="https://www.notion.so/f5d0517cf805427eb4dfb4aedf1604bd" class="ColumnList"><div id="https://www.notion.so/7b614854e46f4a9198ad5f422479b778" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/9f64a1de3be34fffa0eae10ca57da0d8" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2e2a8fe7-d335-4499-a249-b381224cc1e4%2Fpark_ranger.jpg?width=1024&amp;table=block&amp;id=9f64a1de-3be3-4fff-a0ea-e10ca57da0d8"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2e2a8fe7-d335-4499-a249-b381224cc1e4%2Fpark_ranger.jpg?width=1024&amp;table=block&amp;id=9f64a1de-3be3-4fff-a0ea-e10ca57da0d8" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input  (</span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.flickr.com/photos/glaciernps/48490020121">source</a></span><span class="SemanticString"> under Creative Commons CC1)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/0a6aca3f83744edb98c0fcc288bc4b92" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/9d4ebea85ca44467b3aaaa033e86cb04" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fbe25f42c-2ff9-4697-8e38-ece2262aef15%2Fresult_no_grad.png?width=1024&amp;table=block&amp;id=9d4ebea8-5ca4-4467-b3aa-aa033e86cb04"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fbe25f42c-2ff9-4697-8e38-ece2262aef15%2Fresult_no_grad.png?width=1024&amp;table=block&amp;id=9d4ebea8-5ca4-4467-b3aa-aa033e86cb04" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result (background is too blurry)</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/2035fa16bc764188a7bbac723075eae5" class="ColumnList"><div id="https://www.notion.so/81d12519de29441ba5a23fec4218297d" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/a56a21d679a546a885c455761b3b699d" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa232314c-7c68-4240-9f99-feff3818ecd6%2FIMG_0815.jpg?width=2316&amp;table=block&amp;id=a56a21d6-79a5-46a8-85c4-55761b3b699d"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa232314c-7c68-4240-9f99-feff3818ecd6%2FIMG_0815.jpg?width=2316&amp;table=block&amp;id=a56a21d6-79a5-46a8-85c4-55761b3b699d" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">input  (iPhone XR)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/3dfd22c3650d4dc1aac63dd0f225f810" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/3168d9ce42214354b9ed171ef24cf4a5" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F45ff9ec9-b785-4dc9-bde8-741dfc4720c6%2Fresult_me_buddha.png?width=2316&amp;table=block&amp;id=3168d9ce-4221-4354-b9ed-171ef24cf4a5"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F45ff9ec9-b785-4dc9-bde8-741dfc4720c6%2Fresult_me_buddha.png?width=2316&amp;table=block&amp;id=3168d9ce-4221-4354-b9ed-171ef24cf4a5" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">result (buddha&#x27;s body is blurry)</span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/c0f36d1f566b4db58c12de35e5c4a8a0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/818915f9390b4ae29a370c497f7fc8c9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/818915f9390b4ae29a370c497f7fc8c9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">less is more</span></span></h3><div id="https://www.notion.so/e6665b3a774f41978e83df573dbd78a0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">One might think that characterizing this as &quot;</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">enhancing&quot; </em></span><span class="SemanticString">the image is a bit dubious. It is in part a subjective claim. However, consider that we are conditioned to believe that one often needs to add something extraneous to enhance. But, the definition of enhance is plainly to improve the quality or value of something. There is beauty in simplicity; hence removing detail in a photo counts as enhancement. Simply, if something doesn&#x27;t add up in your photo start subtracting.</span></span></p></div><div id="https://www.notion.so/f7d67b78962144b68312c24b7590457b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/200bd230ce7c41cf87ea445febfb7bd4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Cheers,</span></span></p></div><div id="https://www.notion.so/63bd0b5394124779ad404a023152adf8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Sesh</span></span></p></div><div id="https://www.notion.so/48b6b2f57be247acb4632288729cc7fe" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>
      <br/><hr class="style14"/>


    <div id="disqus_thread" width='200' class="PageRoot"></div>
    <script>
        var disqus_config = function () {
        this.page.url = 'https://seshadri.xyz/ml-photo-filter.html';  // page's canonical URL variable
        this.page.identifier = 'ml-photo-filter.html'; // page's unique identifier variable
        };
        
        (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://seshadri-xyz.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  <footer class="Footer">
        <div>&copy; less. but better 2019</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>